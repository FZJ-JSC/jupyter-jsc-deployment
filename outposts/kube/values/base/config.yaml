outpostConfig: |-
  import os
  import shutil

  from kubespawner import KubeSpawner


  class HealthCheckFilter(logging.Filter):
      def filter(self, record: logging.LogRecord) -> bool:
          return record.getMessage().find("/ping") == -1


  # Remove health from application server logs
  logging.getLogger("uvicorn.access").addFilter(HealthCheckFilter()) 

  logged_logger_name = os.environ.get("LOGGER_NAME", "Outpost")
  c.JupyterHubOutpost.log_format = f"%(color)s[%(levelname)1.1s %(asctime)s.%(msecs).03d {logged_logger_name} %(name)s %(module)s:%(lineno)d]%(end_color)s %(message)s"


  async def flavors_update_token(jupyterhub_name):
      token = os.environ.get(f"FLAVOR_{jupyterhub_name.upper()}_AUTH_TOKEN", "")
      if not token:
          raise Exception(f"Flavor auth token for {jupyterhub_name} not configured.")
      return token


  async def flavors(jupyterhub_name):
      if jupyterhub_name == "jupyterjsc":
          return {"typea": 5, "typeb": 5}
      elif jupyterhub_name == "juniq":
          return {"typea": 1, "typeb": 1}
      else:
          return {}


  c.JupyterHubOutpost.flavors_update_token = flavors_update_token
  c.JupyterHubOutpost.flavors = flavors
         
  c.JupyterHubOutpost.spawner_class = KubeSpawner

  c.KubeSpawner.image = "registry.jsc.fz-juelich.de/jupyterjsc/k8s/images/user-jupyterlab:lmod-4.0.2"
  c.KubeSpawner.image_pull_policy = "Always"
  c.KubeSpawner.node_selector = {"usernode": "true"}
  c.KubeSpawner.tolerations = [
      {"key": "usernode", "value": "true", "effect": "NoExecute"}
  ]

  c.KubeSpawner.cpu_guarantee = 0.1
  c.KubeSpawner.cpu_limit = 2
  c.KubeSpawner.mem_guarantee = "512M"
  c.KubeSpawner.mem_limit = "4096M"

  c.KubeSpawner.fs_gid = 100
  c.KubeSpawner.container_security_context = {
      "allowPrivilegeEscalation": True,
      "privileged": True,
      "capabilities": {
          "add": ["CAP_SYS_ADMIN"]
      }
  }

  # Might need longer delete grace periods for unmounting in production
  # c.KubeSpawner.delete_grace_period = 5
  c.KubeSpawner.lifecycle_hooks = {
      "preStop": {
          "exec": {
              "command": ["/bin/sh", "-c", "kill $(ps x | grep '[t]imeout .* jupyterhub-singleuser' | awk '{print $1}')"]
          }
      }
  }


  def pre_spawn_hook(spawner):
      userhome_base = "/p/home/jusers"
      hub = spawner.extra_labels.get("app", "jupyter")
      stage = "staging"
      userid = str(spawner.user.id)
      service = spawner.user_options.get("service", "")

      userhome_dir = os.path.join(userhome_base, hub, stage, userid)
      userhome_skel = f"{userhome_base}/skel/{service}"
      userhome_uid = 1000
      userhome_gid = 1000

      if not os.path.exists(userhome_dir):
          spawner.log.info(f"Create home directory {userhome_dir}")
          os.makedirs(userhome_skel, exist_ok=True)
          shutil.copytree(src=userhome_skel, dst=userhome_dir)
          for dirpath, dirnames, filenames in os.walk(userhome_dir):
              shutil.chown(dirpath, userhome_uid, userhome_gid)
              for filename in filenames:
                  shutil.chown(os.path.join(dirpath, filename), userhome_uid, userhome_gid)


  c.KubeSpawner.pre_spawn_hook = pre_spawn_hook


  def get_profile_volume_mounts(profile):
      common_mounts = [
          {
              "name": "nfs-software", 
              "mountPath": "/p/software/jsccloud", 
              "readOnly": True
          },
          {
              "name": "uftp", 
              "mountPath": "/tmp/custom/uftp.py",
              "subPath": "uftp.py"
          },
          {
              "name": "nfs-userhome",
              "mountPath": "/p/home/jusers",
              "readOnly": False 
          }
      ]
      profile_mounts = [
        {
              "name": f"modules-{profile}", 
              "mountPath": "/tmp/custom/load_jupyter_version.sh", 
              "subPath": "load_jupyter_version.sh"
          },
          {
              "name": f"modules-user-{profile}", 
              "mountPath": "/tmp/custom/load_jupyter_modules.sh",
              "subPath": "load_jupyter_modules.sh"
          } 
      ]
      return common_mounts + profile_mounts
  

  def get_profile_volumes(profile):
      common_volumes = [
          {
              "name": "nfs-software", 
              "hostPath": {
                  "path": "/p/software/jsccloud", 
                  "type": ""
              }
          },
          {
              "name": "uftp", 
              "configMap": {
                  "defaultMode": 292,
                  "name": "uftp"
              }
          },
          {
              "name": "nfs-userhome", 
              "hostPath": {
                  # userid gets expanded by KubeSpawner
                  "path": "/p/home/jusers/jupyterjsc/{userid}", 
                  "type": ""
              }
          }
      ]
      profile_volumes = [
        {
              "name": f"modules-{profile}", 
              "configMap": {
                  "defaultMode": 292,
                  "name": f"modules-{profile}"
              }
          },
          {
              "name": f"modules-user-{profile}", 
              "configMap": {
                  "defaultMode": 292,
                  "name": f"modules-user-{profile}"
              }
          } 
      ]
      return common_volumes + profile_volumes


  c.KubeSpawner.profile_list = [
      {
          "display_name": "JupyterLab - 3.6",
          "slug": "JupyterLab/3.6",
          "kubespawner_override": {
              "volume_mounts": get_profile_volume_mounts("3-6"),
              "volumes": get_profile_volumes("3-6")
          }
      }
  ]


