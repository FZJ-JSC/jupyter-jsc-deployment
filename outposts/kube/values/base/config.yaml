outpostConfig: |-
  import logging
  import os
  import shutil
  import yaml

  from kubespawner import KubeSpawner

  ##########
  # Logging
  ##########
  class HealthCheckFilter(logging.Filter):
      def filter(self, record: logging.LogRecord) -> bool:
          return record.getMessage().find("/ping") == -1

  class EventsCheckFilter(logging.Filter):
      def filter(self, record: logging.LogRecord) -> bool:
          if record.funcName in ["_watch_and_update"]:
              return False
          return True

  # Remove health from application server logs
  logging.getLogger("uvicorn.access").addFilter(HealthCheckFilter())

  logger_name = os.environ.get("LOGGER_NAME", "JupyterHubOutpost")
  logging.getLogger(logger_name).addFilter(EventsCheckFilter())

  logged_logger_name = os.environ.get("LOGGER_NAME", "Outpost")
  c.JupyterHubOutpost.log_format = f"%(color)s[%(levelname)1.1s %(asctime)s.%(msecs).03d {logged_logger_name} %(name)s %(module)s:%(lineno)d]%(end_color)s %(message)s"

  ##########
  # Flavors
  ##########

  # Used to send update of the current usage to JHub during start/stop
  async def flavors_update_token(jupyterhub_name):
      token = os.environ.get(f"FLAVOR_{jupyterhub_name.upper()}_AUTH_TOKEN", "")
      if not token:
          raise Exception(f"Flavor auth token for {jupyterhub_name} not configured.")
      return token

  # Specific flavors for users, or disable it completely for specific users
  async def flavors_per_user(outpost, jupyterhub_name, authentication):
      import copy
      hub_flavors = await outpost.get_flavors(jupyterhub_name)
      
      with open("/mnt/flavors/flavors.yaml", "r") as f:
          flavor_config = yaml.full_load(f)

      user_sets = []
      # check if the given user is part of any user set
      for key, value in flavor_config.get("users", {}).items():
          if authentication.get('name', 'unknown_user') in value.get("usernames", []):
              user_sets.append((key, value.get("weight", 0)))
          else:
              for user_group in authentication.get('groups', []):
                  if user_group in value.get("groups", []):
                      user_sets.append((key, value.get("weight", 0)))
                      break
      
      if len(user_sets) == 0:
          return hub_flavors

      user_flavors = copy.deepcopy(hub_flavors)

      user_sets = sorted(
          user_sets,
          key=lambda x: x[1]
      )
      # sorted sorts ascending, we're using weight, so we use the last element
      # with the biggest weight
      user_set = user_sets[-1][0]


      # When "disable" is true, we return an empty dict for this uset_set
      authentication_log = copy.deepcopy(authentication)
      if "access_token" in authentication_log.keys():
          del authentication_log["access_token"]
      if flavor_config.get("users", {}).get(user_set, {}).get("disable", False):
          outpost.log.debug(f"Specific user not allowed to use any flavors. Userset {user_set}. Used authentication dict: {authentication_log}")
          return {}

      outpost.log.debug(f"Use user specific flavor userset {user_set}. Used authentication dict: {authentication_log}")

      for flavorName, overrideDict in flavor_config.get("users", {}).get(user_set, {}).get("flavors", {}).items():
          if flavorName not in user_flavors.keys():
              user_flavors[flavorName] = {}
          for overrideKey, overrideValue in overrideDict.items():
              user_flavors[flavorName][overrideKey] = overrideValue
      
      return user_flavors

  # Default flavors per JupyterHub
  async def flavors_per_hub(jupyterhub_name):
      with open("/mnt/flavors/flavors.yaml", "r") as f:
          flavor_config = yaml.full_load(f)
      
      jupyterhub_sets = []
      # check if the given jupyterhub_name is part of any jhub set
      for key, value in flavor_config.get("hubs", {}).items():
          if jupyterhub_name in value.get("jupyterhubs", []):
              jupyterhub_sets.append((key, value.get("weight", 0)))
      
      # jupyterhub_name is not allowed to use any flavors 
      if len(jupyterhub_sets) == 0:
          return {}
      
      jupyterhub_sets = sorted(
          jupyterhub_sets,
          key=lambda x: x[1]
      )
      # sorted sorts ascending, we're using weight, so we use the last element
      # with the biggest weight
      jupyterhub_set = jupyterhub_sets[-1][0]
      
      hub_specific_flavors = {}
      for flavorName in flavor_config.get("hubs", {}).get(jupyterhub_set, {}).get("flavors", []):
          if flavorName in flavor_config.get("flavors", {}).keys():
              hub_specific_flavors[flavorName] = flavor_config["flavors"][flavorName]
      
      return hub_specific_flavors

  def get_flavor_resources(flavor):
      with open("/mnt/flavors/flavors.yaml", "r") as f:
          flavor_config = yaml.full_load(f)
      
      if flavor not in flavor_config.get("flavors", {}).keys():
          raise Exception(f"Flavor {flavor} not configured. Abort start.")
      
      return flavor_config["flavors"][flavor].get("resources", {})

  c.JupyterHubOutpost.flavors_update_token = flavors_update_token
  c.JupyterHubOutpost.flavors = flavors_per_hub
  c.JupyterHubOutpost.user_flavors = flavors_per_user
  c.JupyterHubOutpost.flavors_undefined_max = 0


  ##########
  # KubeSpawner
  ##########
  c.JupyterHubOutpost.spawner_class = KubeSpawner

  c.KubeSpawner.image = "registry.jsc.fz-juelich.de/jupyterjsc/k8s/images/user-jupyterlab:lmod-4.0.5"
  c.KubeSpawner.image_pull_policy = "Always"
  c.KubeSpawner.tolerations = [
      {"key": "usernode", "value": "true", "effect": "NoExecute"}
  ]
  # We set all the labels we want in extra_labels, so overwrite common_labels
  c.KubeSpawner.common_labels = {}

  c.KubeSpawner.secret_name_template = "tls-{userid}-{servername}"
  c.KubeSpawner.start_timeout = 600
  c.KubeSpawner.fs_gid = 100
  c.KubeSpawner.container_security_context = {
      "allowPrivilegeEscalation": True,
      "privileged": True,
      "capabilities": {
          "add": ["CAP_SYS_ADMIN"]
      }
  }

  c.KubeSpawner.extra_pod_config = {
      "restartPolicy": "Always",
  }
  c.KubeSpawner.delete_grace_period = 20
  c.KubeSpawner.lifecycle_hooks = {
      "preStop": {
          "exec": {
              "command": ["/bin/sh", "-c", "kill $(ps x | grep '[j]upyterhub-singleuser' | awk '{print $1}')"]
          }
      }
  }


  ##########
  # KubeSpawner prespawn hook
  ##########

  def pre_spawn_hook(spawner):
      userhome_base = "/p/home/jusers"
      hub = spawner.extra_labels.get("app", "jupyter")
      stage = os.environ.get("STAGE", "staging")
      userid = str(spawner.user.id)
      profile = spawner.user_options.get("profile", "")
      try:
          service = profile.split("/")[0].lower()
      except:
          spawner.log.exception(f"{spawner._log_name} - Use default service: jupyterlab for skeleton dir")
          service = "jupyterlab"

      userhome_dir = os.path.join(userhome_base, hub, stage, userid)
      userhome_skel = f"{userhome_base}/skel/{service}"
      userhome_uid = 1000
      userhome_gid = 1000

      def copy_file(src, dst):
          if os.path.isfile(src):
              shutil.copyfile(src=src, dst=dst)
              shutil.chown(dst, userhome_uid, userhome_gid)

      def copy_dir(src, dst):
          if os.path.isdir(src):
              shutil.copytree(src=src, dst=dst)
              for dirpath, dirnames, filenames in os.walk(dst):
                  shutil.chown(dirpath, userhome_uid, userhome_gid)
                  for filename in filenames:
                      shutil.chown(os.path.join(dirpath, filename), userhome_uid, userhome_gid)

      if not os.path.exists(userhome_dir):
          spawner.log.info(f"{spawner._log_name} - Create home directory {userhome_dir}")
          os.makedirs(userhome_skel, exist_ok=True)
          copy_dir(userhome_skel, userhome_dir)
      else:
          # Update motd
          copy_file(f"{userhome_skel.rstrip('/')}/.motd", f"{userhome_dir.rstrip('/')}/.motd")
          shutil.rmtree(f"{userhome_dir.rstrip('/')}/.motd.d", ignore_errors=True)
          copy_dir(f"{userhome_skel.rstrip('/')}/.motd.d", f"{userhome_dir.rstrip('/')}/.motd.d")

      if "usermount_path" in spawner.user_options:
          del spawner.user_options["usermount_path"]

  c.KubeSpawner.pre_spawn_hook = pre_spawn_hook


  ##########
  # KubeSpawner profiles
  ##########

  def get_profile(spawner):
      profile = spawner.user_options.get("profile", "JupyterLab/3.6")
      if "/" in profile:
          profile = '-'.join(profile.split("/")[1:])
      profile = profile.replace(".", "-")
      return profile


  def get_profile_volume_mounts(spawner):
      profile = get_profile(spawner)
      if profile == "custom":
          if "userdata_path" in spawner.user_options:
              userdata_mount = [
                  {
                      "name": "nfs-userdata",
                      "mountPath": spawner.user_options["userdata_path"],
                      "readOnly": False 
                  }
              ]
              return userdata_mount
          else:
              return []
      else:
          common_mounts = [
              {
                  "name": "nfs-software", 
                  "mountPath": "/p/software/jsccloud", 
                  "readOnly": True
              },
              {
                  "name": "uftp", 
                  "mountPath": "/tmp/custom/uftp.py",
                  "subPath": "uftp.py"
              },
              {
                  "name": "nfs-userhome",
                  "mountPath": "/home/jovyan",
                  "readOnly": False 
              }
          ]
          profile_mounts = [
          {
                  "name": f"modules-{profile}", 
                  "mountPath": "/tmp/custom/load_jupyter_version.sh", 
                  "subPath": "load_jupyter_version.sh"
              },
              {
                  "name": f"modules-user-{profile}", 
                  "mountPath": "/tmp/custom/load_jupyter_modules.sh",
                  "subPath": "load_jupyter_modules.sh"
              }
          ]
          return common_mounts + profile_mounts

  def get_profile_volumes(spawner, jupyterhub_name):
      profile = get_profile(spawner)
      stage = os.environ.get("STAGE", "staging")

      if profile == "custom":
          if "userdata_path" in spawner.user_options:
              userdata_volume = [
              {
                  "name": "nfs-userdata", 
                  "hostPath": {
                      # userid gets expanded by KubeSpawner, do not use mapped 
                      # hub name here, each hub uses it's own home dir.
                      "path": f"/p/home/jusers/{jupyterhub_name}/{stage}/{{userid}}", 
                      "type": ""
                  }
              }
              ]
              return userdata_volume
          else:
              return []
      else:   
          map_hub_names = {
              "jupyterjsc": "defaulthub",
              "coec": "defaulthub",
              "coeraise": "defaulthub",
              "portalgauss": "defaulthub",
              "euroccgcs": "defaulthub",
              "dev1": "defaulthub",
              "dev2": "defaulthub"
          }
          hub = map_hub_names.get(jupyterhub_name, jupyterhub_name)

          common_volumes = [
              {
                  "name": "nfs-software", 
                  "hostPath": {
                      "path": "/p/software/jsccloud", 
                      "type": ""
                  }
              },
              {
                  "name": "uftp", 
                  "configMap": {
                      "defaultMode": 292,
                      "name": "uftp"
                  }
              },
              {
                  "name": "nfs-userhome", 
                  "hostPath": {
                      # userid gets expanded by KubeSpawner, do not use mapped 
                      # hub name here, each hub uses it's own home dir.
                      "path": f"/p/home/jusers/{jupyterhub_name}/{stage}/{{userid}}", 
                      "type": ""
                  }
              }
          ]
          profile_volumes = [
              {
                  "name": f"modules-{profile}", 
                  "configMap": {
                      "defaultMode": 292,
                      "name": f"modules-{hub}-{profile}"
                  }
              },
              {
                  "name": f"modules-user-{profile}", 
                  "configMap": {
                      "defaultMode": 292,
                      "name": f"modules-user-{hub}-{profile}"
                  }
              }
          ]
          return common_volumes + profile_volumes

  def get_node_selector(spawner, jupyterhub_name, resources, flavor):
      from kubernetes import client
      from kubernetes import config
      import json

      config.load_incluster_config()
      core = client.CoreV1Api()
      flavor_mem_request = resources.get("mem_guarantee", "0M")
      spawner.log.info(f"{spawner._log_name} - {flavor_mem_request}M memory for {flavor} ({jupyterhub_name}) requested")
      base_node_name = "usernode-"
      
      first_node = True
      outpost_mem_blocked = 1024
      for i in range(0, 51):
          node_name = f"{base_node_name}{i}"
          try:
              node = core.read_node_status(node_name)
          except:
              spawner.log.info(f"{spawner._log_name} - Could not load node {node_name}")
              continue
          requested_mem_mi_s = json.loads(node.metadata.annotations.get("management.cattle.io/pod-requests", '{}')).get("memory", "0Mi")
          total_mem_ki_s = node.status.allocatable.get("memory", "0Ki") # 8128016
          free_mem_mi = int(total_mem_ki_s[:-2])/1024 - int(requested_mem_mi_s[:-2])
          free_mem_m = free_mem_mi*1.04858
          if first_node:
              first_node = False
              spawner.log.info(f"{spawner._log_name} - {node_name} - keep {outpost_mem_blocked} free for JupyterHub Outpost")
              free_mem_m = free_mem_m - outpost_mem_blocked
          spawner.log.info(f"{spawner._log_name} - {node_name} has {free_mem_m}M free memory.")
          if free_mem_m > int(flavor_mem_request[:-1]):
              spawner.log.info(f"{spawner._log_name} - Use {node_name}")
              return {"kubernetes.io/hostname": node_name}
          else:
              spawner.log.info(f"{spawner._log_name} - Do not use {node_name}")
      spawner.log.warning("{spawner._log_name} - Use kubernetes scheduler to place node")
      return {"usernode": "true"}

  async def profile_list(spawner):
      # We're loading this config file for each Spawner object
      # Therefore, it's fine to just create one profile
      jupyterhub_name = spawner.jupyterhub_name
      profile = get_profile(spawner)
      flavor = spawner.user_options.get("flavor", "default")
      resources = get_flavor_resources(flavor)

      if profile == "custom":
          return [
              {
                  "display_name": "JupyterLab - custom",
                  "slug": "JupyterLab/custom",
                  "kubespawner_override": {
                      "image": spawner.user_options["image"],
                      "volume_mounts": get_profile_volume_mounts(spawner),
                      "volumes": get_profile_volumes(spawner, jupyterhub_name),
                      "node_selector": get_node_selector(spawner, jupyterhub_name, resources, flavor),
                      "cpu_guarantee": resources["cpu_guarantee"],
                      "cpu_limit": resources["cpu_limit"],
                      "mem_guarantee": resources["mem_guarantee"],
                      "mem_limit": resources["mem_limit"]
                  }
              }
          ]
      else:
          return [
              {
                  "display_name": "JupyterLab - 3.6",
                  "slug": "JupyterLab/3.6",
                  "kubespawner_override": {
                      "volume_mounts": get_profile_volume_mounts(spawner),
                      "volumes": get_profile_volumes(spawner, jupyterhub_name),
                      "node_selector": get_node_selector(spawner, jupyterhub_name, resources, flavor),
                      "cpu_guarantee": resources["cpu_guarantee"],
                      "cpu_limit": resources["cpu_limit"],
                      "mem_guarantee": resources["mem_guarantee"],
                      "mem_limit": resources["mem_limit"]
                  }
              }
          ]

  c.KubeSpawner.profile_list = profile_list
