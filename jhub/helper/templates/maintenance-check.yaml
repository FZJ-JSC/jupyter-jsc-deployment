apiVersion: v1
kind: ConfigMap
metadata:
  name: jupyterhub-incident-check  
data:
  run.sh: |
    #!/bin/sh

    while [ ! -d ${STATIC_IMG_DIR} ]; do echo "Waiting for ${STATIC_IMG_DIR} ..." ; sleep 5; done

    SLEEP=$(/usr/local/bin/python3 -c 'import json, os; f=open(os.environ["CUSTOM_CONFIG_PATH"], "r"); config = json.load(f); f.close(); print(config["incident-check"].get("interval", 60))')
    while true
    do
        echo "$(date) - Run incident check ..."
        /usr/local/bin/python3 -u /mnt/incidents/incident_check.py
        echo "$(date) - Run incident check ... done"
        sleep ${SLEEP}
    done

  incident_check.py: |
    # Update incidents every n seconds
    import fcntl
    import json
    import logging.handlers
    import os
    import shutil
    import socket
    import sys
    import time

    import requests
    from dateutil import parser
    from jsonformatter import JsonFormatter

    LOGGER_NAME = os.environ.get("LOGGER_NAME", "IncidentCheck")
    log = logging.getLogger(LOGGER_NAME)
    log.level = 20

    supported_handler_classes = {
        "stream": logging.StreamHandler,
        "file": logging.handlers.TimedRotatingFileHandler,
        "smtp": logging.handlers.SMTPHandler,
        "syslog": logging.handlers.SysLogHandler,
    }

    # supported formatters and their arguments
    supported_formatter_classes = {"json": JsonFormatter, "simple": logging.Formatter}
    json_fmt = '{"asctime": "asctime", "levelno": "levelno", "levelname": "levelname", "logger": "name", "file": "pathname", "line": "lineno", "function": "funcName", "Message": "message"}'
    simple_fmt = "%(asctime)s logger=%(name)s levelno=%(levelno)s levelname=%(levelname)s file=%(pathname)s line=%(lineno)d function=%(funcName)s : %(message)s"
    supported_formatter_kwargs = {
        "json": {"fmt": json_fmt},
        "simple": {"fmt": simple_fmt},
    }


    def setup_logger(handler_name, configuration):
        configuration_logs = {"configuration": str(configuration)}
        formatter_name = configuration.pop("formatter")
        level = configuration.pop("level")

        # catch some special cases
        for key, value in configuration.items():
            if key == "stream":
                if value == "ext://sys.stdout":
                    configuration["stream"] = sys.stdout
                elif value == "ext://sys.stderr":
                    configuration["stream"] = sys.stderr
            elif key == "socktype":
                if value == "ext://socket.SOCK_STREAM":
                    configuration["socktype"] = socket.SOCK_STREAM
                elif value == "ext://socket.SOCK_DGRAM":
                    configuration["socktype"] = socket.SOCK_DGRAM
            elif key == "address":
                configuration["address"] = tuple(value)
        handler = supported_handler_classes[handler_name](**configuration)
        formatter = supported_formatter_classes[formatter_name](
            **supported_formatter_kwargs[formatter_name]
        )
        handler.name = handler_name
        handler.setLevel(level)
        handler.setFormatter(formatter)
        logger = logging.getLogger(LOGGER_NAME)
        logger.addHandler(handler)
        log.debug(f"Logging handler added ({handler_name}): {configuration_logs}")


    def acquireReadLock(filename):
        """acquire exclusive lock file access"""
        if not os.path.exists(filename):
            with open(filename, "w") as f:
                f.write("")
        locked_file_descriptor = open(filename, "r+")
        fcntl.lockf(locked_file_descriptor, fcntl.LOCK_EX)
        return locked_file_descriptor


    def acquireLock(filename):
        """acquire exclusive lock file access"""
        if not os.path.exists(filename):
            with open(filename, "w") as f:
                f.write("")
        locked_file_descriptor = open(filename, "w+")
        fcntl.lockf(locked_file_descriptor, fcntl.LOCK_EX)
        return locked_file_descriptor


    def releaseLock(locked_file_descriptor):
        """release exclusive lock file access"""
        if locked_file_descriptor:
            locked_file_descriptor.close()


    def write_to_file(filename, fileinput):
        log.debug(f"Write to file {filename}: {fileinput}")
        try:
            lock_fd = acquireLock(filename) or None
            lock_fd.write(fileinput)
        except:
            log.exception(f"Could not write to file {filename}")
        finally:
            releaseLock(lock_fd)


    def read_json_file(filename):
        try:
            lock_fd = acquireReadLock(filename) or None
            with open(filename, "r") as f:
                ret = json.load(f)
        except:
            log.exception(f"Could not read from file {filename}")
            ret = None
        finally:
            releaseLock(lock_fd)
        return ret


    def update_status_file(system, output_dir, health):
        systems_status_list_update = read_json_file(
            f"{output_dir}/status.json"
        )
        systems_status_list_update.update({system.upper(): health})
        log.info(f"Write to status.json: {systems_status_list_update}")
        write_to_file(
            f"{output_dir}/status.json",
            json.dumps(systems_status_list_update),
        )


    def update_status_image(system, static_dir, health):
        image_path = f"{static_dir}/systems/{system.lower()}.svg"
        # 0: Healthy, 10: Annotation, 20: Minor, 30: Medium, 40: Major, 50: Critical
        template_path = f"{static_dir}/templates/{health}.svg"
        try:
            log.info(f"Copy {template_path} to {image_path}")
            shutil.copyfile(template_path, image_path)
        except:
            log.exception(f"Could not copy {template_path} to {image_path}")


    def update_status(system, output_dir, svc, systems_status_list, static_dir):
        if svc["health"] != systems_status_list.get(system.upper(), None):
            update_status_file(system, output_dir, svc["health"])
            update_status_image(system, static_dir, svc["health"])


    def update_incident_systems_file(
        system, output_dir, svc, systems_incidents_list, incident_threshold
    ):
        if svc["health"] > incident_threshold:
            # System is over incident threshold, but not in the list
            if system.upper() not in systems_incidents_list:
                systems_incidents_list_update = read_json_file(
                    f"{output_dir}/active_incidents.json"
                )
                systems_incidents_list_update.append(system.upper())
                log.info(f"Write to active_incidents.json: {systems_incidents_list_update}")
                write_to_file(
                    f"{output_dir}/active_incidents.json",
                    json.dumps(systems_incidents_list_update),
                )
        else:
            # System is not over incident threshold, but still in the list
            if system.upper() in systems_incidents_list:
                systems_incidents_list_prev = read_json_file(
                    f"{output_dir}/active_incidents.json"
                )
                systems_incidents_list_new = [
                    x for x in systems_incidents_list_prev if x != system.upper()
                ]
                log.info(
                    f"Write to {output_dir}/active_incidents.json: {systems_incidents_list_new}"
                )
                write_to_file(
                    f"{output_dir}/active_incidents.json",
                    json.dumps(systems_incidents_list_new),
                )


    def setup_incident(incidents_list, system, output_dir):
        if len(incidents_list) > 1:
            log.warning(
                "Multiple active incidents. Use first one in list"
            )
        incident = incidents_list[0]
        short_description = incident["short_description"]
        if short_description:
            description = short_description
        else:
            description = incident["description"]
        start_time = incident["start_time"]
        if incident["end_time"]:
            end_time = incident["end_time"]
        else:
            end_time = "unknown"
        info_msg = f"{start_time} - {end_time}: {description}"
        write_to_file(f"{output_dir}/{system.upper()}.txt", info_msg)


    def no_incidents(system, output_dir):
        write_to_file(f"{output_dir}/{system.upper()}.txt", "")


    def update_incidents(name, svc, active_svc_incidents, incident_threshold, systems_incidents_list, output_dir):
        update_incident_systems_file(name, output_dir, svc, systems_incidents_list, incident_threshold)
        active_incidents_over_threshold = [
            x
            for x in active_svc_incidents
            if x["incident_severity"] > incident_threshold
        ]
        if active_incidents_over_threshold:
            log.debug(
                "Found active incident(s) over incident threshold"
            )
            setup_incident(active_incidents_over_threshold, name, output_dir)
            return
        next_maintenance = svc["next_maintenance"]
        if next_maintenance:
            next_maintenance_incidents = [
                x
                for x in active_svc_incidents
                if parser.parse(x["start_time"]) == parser.parse(next_maintenance)
            ]
            if len(next_maintenance_incidents) == 0:
                raise Exception(f"Could not find matching start time in incidents for maintenance for {name}")
            log.debug(
                "Found announced maintenance(s)"
            )
            setup_incident(next_maintenance_incidents, name, output_dir)
            return
        no_incidents(name, output_dir)


    def check_incidents(config_mc, output_dir, static_dir):
        api_url = config_mc.get("url", "https://status.jsc.fz-juelich.de/api")
        incident_threshold = config_mc.get("health_threshold", 0)
        systems_incidents_list = read_json_file(f"{output_dir}/active_incidents.json")
        systems_status_list = read_json_file(f"{output_dir}/status.json")
        try:
            all_incidents_r = requests.get(f"{api_url}/incidents", timeout=5)
            all_incidents_r.raise_for_status()
            all_incidents = all_incidents_r.json()
            for name, id in config_mc["services"].items():
                try:
                    svc_r = requests.get(f"{api_url}/services/{id}", timeout=5)
                    svc_r.raise_for_status()
                    svc = svc_r.json()
                    active_svc_incidents = [
                        x for x in all_incidents 
                            if int(id) in x.get("affected_services", []) 
                            and not x.get("resolved", "")
                    ]

                    update_status(name, output_dir, svc, systems_status_list, static_dir)
                    update_incidents(name, svc, active_svc_incidents, incident_threshold, systems_incidents_list, output_dir)
                except:
                    log.exception(f"Could not check for incidents for {name}")
        except:
            log.exception("Could not check for incidents")


    if __name__ == "__main__":
        with open(os.environ["CUSTOM_CONFIG_PATH"], "r") as f:
            config = json.load(f)
        output_dir = os.environ["OUTPUT_DIR"]
        static_dir = os.environ["STATIC_IMG_DIR"]
        incidents_json = f"{output_dir}/active_incidents.json"
        status_json = f"{output_dir}/status.json"
        for name, logger_config in config["incident-check"].get("logger", {}).items():
            setup_logger(name, logger_config)
        for json_file in [incidents_json, status_json]:
            if not os.path.exists(json_file):
                with open(json_file, "w") as f:
                    dump = [] if json_file == incidents_json else {}
                    f.write(json.dumps(dump))
            if not os.path.isfile(json_file):
                log.error(f"{json_file} must be a file. Exit")
                exit(1)
        # while True:
        check_incidents(config["incident-check"], output_dir, static_dir)
        # time.sleep(config["incident-check"].get("interval", 60))